{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ef0a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69dbd509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: is_ongehuwd() results for sample texts:\n",
      "'Ongehuwd gebleven': True\n",
      "'ongehuwd   gebleven': True\n",
      "'ongehuwd- gebleven': True\n",
      "'ongehuwd gebleeven': True\n",
      "'nog iets anders': False\n",
      "'Test: ongehuwd gebleven!': True\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Optionally use fuzzy matching if available.\n",
    "try:\n",
    "    from fuzzywuzzy import fuzz\n",
    "    FUZZY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    import difflib\n",
    "    FUZZY_AVAILABLE = False\n",
    "\n",
    "def is_ongehuwd(text, target=\"ongehuwd gebleven\", threshold=70):\n",
    "    \"\"\"\n",
    "    Determine whether a text indicates an 'ongehuwd gebleven' note,\n",
    "    even if there are extra characters or minor misspellings.\n",
    "\n",
    "    Strategy:\n",
    "      1. Lowercase the text and check if both \"ongehuwd\" and \"gebleven\" appear.\n",
    "      2. If not found exactly, use fuzzy matching (if available) with a lower threshold.\n",
    "    \n",
    "    Parameters:\n",
    "      text (str): The text from the 'nama orang' field.\n",
    "      target (str): The target phrase.\n",
    "      threshold (int): For fuzzy matching, the minimum score required (0-100 scale).\n",
    "    \n",
    "    Returns:\n",
    "      bool: True if the text is considered to match, False otherwise.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return False\n",
    "    text_lower = text.lower()\n",
    "    # Basic substring check that allows extra characters and spaces.\n",
    "    if \"ongehuwd\" in text_lower and \"gebleven\" in text_lower:\n",
    "        return True\n",
    "    \n",
    "    # Fallback: fuzzy matching if the exact substrings are not found.\n",
    "    if FUZZY_AVAILABLE:\n",
    "        score = fuzz.partial_ratio(text_lower, target.lower())\n",
    "        return score >= threshold\n",
    "    else:\n",
    "        # Use difflib as a fallback. difflib returns a ratio between 0 and 1.\n",
    "        ratio = difflib.SequenceMatcher(None, text_lower, target.lower()).ratio()\n",
    "        return ratio >= (threshold / 100.0)\n",
    "\n",
    "# (Optional) Debug test cases for the helper function.\n",
    "test_texts = [\n",
    "    \"Ongehuwd gebleven\",\n",
    "    \"ongehuwd   gebleven\",\n",
    "    \"ongehuwd- gebleven\",\n",
    "    \"ongehuwd gebleeven\",  # slight misspelling\n",
    "    \"nog iets anders\",\n",
    "    \"Test: ongehuwd gebleven!\",\n",
    "]\n",
    "print(\"Debug: is_ongehuwd() results for sample texts:\")\n",
    "for txt in test_texts:\n",
    "    print(f\"'{txt}':\", is_ongehuwd(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8404c394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bio Dataset:\n",
      "                            nama orang   geb/overl.  id  actual id Unnamed: 4\n",
      "0              Aa, zr. W. van der (N)   1908-1942/5   0        NaN        NaN\n",
      "1  Aalbers, dr. Joh. Godefr., arts (N)    1910-1992   1        NaN        NaN\n",
      "2              Aalders, zr. Jacoba (N)    1910-1999   2        NaN        NaN\n",
      "3                    Abeel, David (VS)    1804-1846   3        NaN        NaN\n",
      "4          Abkoude, ds. F.N.M. van (N)    1895-1988   4        NaN        NaN \n",
      "\n",
      "Spouse Dataset:\n",
      "                                  spouse  id\n",
      "0            ~ 1935 Akke Reidinga † 1990   1\n",
      "1          ~ 1918 Regina Horstman † 1988   4\n",
      "2                        ~ Emma Reinmuth   5\n",
      "3         ~ 1888 J.M. de Buisonjé † 1940   7\n",
      "4  ~ 1894 Maria Lambertha Gunning † 1939   8\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "# Set the file paths for your CSV files.\n",
    "bio_file = '/Volumes/Extreme SSD/Python_Projects/NIAA Project/FINAL Data (with annotations)/bio_data - bio_data.csv'\n",
    "spouse_file = '/Volumes/Extreme SSD/Python_Projects/NIAA Project/FINAL Data (with annotations)/spouse_data - spouse_data.csv'\n",
    "\n",
    "# Load the datasets.\n",
    "bio_df = pd.read_csv(bio_file)\n",
    "spouse_df = pd.read_csv(spouse_file)\n",
    "\n",
    "# Display the first few rows of each to confirm the structure.\n",
    "print(\"Bio Dataset:\")\n",
    "print(bio_df.head(), \"\\n\")\n",
    "print(\"Spouse Dataset:\")\n",
    "print(spouse_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f6b78c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended text to bio row with id 39.0\n",
      "Appended text to bio row with id 126.0\n",
      "Appended text to bio row with id 153.0\n",
      "Added spouse row for actual id 316.0 with 'ongehuwd gebleven'\n",
      "Appended text to bio row with id 454.0\n",
      "Appended text to bio row with id 459.0\n",
      "Added spouse row for actual id 488.0 with 'ongehuwd gebleven'\n",
      "Added spouse row for actual id 521.0 with 'ongehuwd gebleven'\n",
      "Appended text to bio row with id 552.0\n",
      "Added spouse row for actual id 559.0 with 'ongehuwd gebleven'\n",
      "Added spouse row for actual id 567.0 with 'ongehuwd gebleven'\n",
      "Added spouse row for actual id 642.0 with 'ongehuwd gebleven'\n",
      "Appended text to bio row with id 651.0\n",
      "Added spouse row for actual id 712.0 with 'ongehuwd gebleven'\n",
      "Added spouse row for actual id 755.0 with 'ongehuwd gebleven'\n",
      "Appended text to bio row with id 790.0\n",
      "Added spouse row for actual id 828.0 with 'ongehuwd gebleven'\n",
      "Added spouse row for actual id 851.0 with 'ongehuwd gebleven'\n",
      "Added spouse row for actual id 864.0 with 'ongehuwd gebleven'\n",
      "Added spouse row for actual id 868.0 with 'ongehuwd gebleven'\n",
      "Appended text to bio row with id 946.0\n",
      "Added spouse row for actual id 966.0 with 'ongehuwd gebleven'\n",
      "Added spouse row for actual id 983.0 with 'ongehuwd gebleven'\n",
      "Added spouse row for actual id 985.0 with 'ongehuwd gebleven'\n",
      "Added spouse row for actual id 987.0 with 'ongehuwd gebleven'\n",
      "Added spouse row for actual id 989.0 with 'ongehuwd gebleven'\n",
      "Added spouse row for actual id 1036.0 with 'ongehuwd gebleven'\n",
      "Added spouse row for actual id 1060.0 with 'ongehuwd gebleven'\n",
      "Appended text to bio row with id 1065.0\n",
      "Appended text to bio row with id 1083.0\n",
      "Appended text to bio row with id 1113.0\n",
      "Appended text to bio row with id 1164.0\n",
      "Added spouse row for actual id 1169.0 with 'ongehuwd gebleven'\n",
      "Added spouse row for actual id 1367.0 with 'ongehuwd gebleven'\n",
      "Added spouse row for actual id 1413.0 with 'ongehuwd gebleven'\n",
      "Added spouse row for actual id 1425.0 with 'ongehuwd gebleven'\n",
      "Added spouse row for actual id 1487.0 with 'ongehuwd gebleven'\n",
      "Added spouse row for actual id 1489.0 with 'ongehuwd gebleven'\n",
      "Added spouse row for actual id 1492.0 with 'ongehuwd gebleven'\n",
      "Appended text to bio row with id 1577.0\n",
      "Appended text to bio row with id 1594.0\n",
      "\n",
      "After processing:\n",
      "Cleaned Bio Dataset Head:\n",
      "                            nama orang   geb/overl.  id  actual id Unnamed: 4\n",
      "0              Aa, zr. W. van der (N)   1908-1942/5   0        NaN        NaN\n",
      "1  Aalbers, dr. Joh. Godefr., arts (N)    1910-1992   1        NaN        NaN\n",
      "2              Aalders, zr. Jacoba (N)    1910-1999   2        NaN        NaN\n",
      "3                    Abeel, David (VS)    1804-1846   3        NaN        NaN\n",
      "4          Abkoude, ds. F.N.M. van (N)    1895-1988   4        NaN        NaN \n",
      "\n",
      "Updated Spouse Dataset Head:\n",
      "                                  spouse   id\n",
      "0            ~ 1935 Akke Reidinga † 1990  1.0\n",
      "1          ~ 1918 Regina Horstman † 1988  4.0\n",
      "2                        ~ Emma Reinmuth  5.0\n",
      "3         ~ 1888 J.M. de Buisonjé † 1940  7.0\n",
      "4  ~ 1894 Maria Lambertha Gunning † 1939  8.0\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "# Define column names per the provided headers.\n",
    "name_col = \"nama orang\"\n",
    "id_col = \"id\"\n",
    "actual_id_col = \"actual id\"\n",
    "\n",
    "# Create a Boolean mask for rows with a non-null 'actual id'.\n",
    "mask_actual_id = bio_df[actual_id_col].notnull()\n",
    "\n",
    "# Process each mistaken row individually.\n",
    "# (A debug print is included so you can verify each processed row. Remove if not needed.)\n",
    "for idx, row in bio_df[mask_actual_id].iterrows():\n",
    "    mistaken_text = row[name_col]\n",
    "    target_id = row[actual_id_col]\n",
    "    \n",
    "    # Debug output to verify processing.\n",
    "    # print(f\"Processing row {idx}: mistaken_text='{mistaken_text}', target_id='{target_id}'\")\n",
    "    \n",
    "    if isinstance(mistaken_text, str) and is_ongehuwd(mistaken_text):\n",
    "        # For rows indicating \"ongehuwd gebleven\", add a new spouse row.\n",
    "        new_spouse_row = {\"id\": target_id, \"spouse\": \"ongehuwd gebleven\"}\n",
    "        spouse_df = pd.concat([spouse_df, pd.DataFrame([new_spouse_row])], ignore_index=True)\n",
    "        # Debug statement:\n",
    "        print(f\"Added spouse row for actual id {target_id} with 'ongehuwd gebleven'\")\n",
    "    else:\n",
    "        # Otherwise, append the mistaken text to the correct bio record.\n",
    "        target_mask = bio_df[id_col] == target_id\n",
    "        if target_mask.any():\n",
    "            bio_df.loc[target_mask, name_col] = (\n",
    "                bio_df.loc[target_mask, name_col].astype(str) + \" \" + mistaken_text\n",
    "            )\n",
    "            print(f\"Appended text to bio row with id {target_id}\")\n",
    "        else:\n",
    "            print(f\"Warning: No matching bio row found for actual id {target_id}\")\n",
    "\n",
    "# Remove mistaken rows (those with non-null 'actual id') from the bio dataset.\n",
    "bio_df_cleaned = bio_df[~mask_actual_id].reset_index(drop=True)\n",
    "\n",
    "print(\"\\nAfter processing:\")\n",
    "print(\"Cleaned Bio Dataset Head:\")\n",
    "print(bio_df_cleaned.head(), \"\\n\")\n",
    "print(\"Updated Spouse Dataset Head:\")\n",
    "print(spouse_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffa2219e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated files have been saved as 'bio_updated.csv' and 'spouse_updated.csv'.\n"
     ]
    }
   ],
   "source": [
    "bio_df_cleaned.to_csv('/Volumes/Extreme SSD/Python_Projects/NIAA Project/FINAL/bio_data_cleaned.csv', index=False)\n",
    "spouse_df.to_csv('/Volumes/Extreme SSD/Python_Projects/NIAA Project/FINAL/spouse_data_cleaned.csv', index=False)\n",
    "print(\"Updated files have been saved as 'bio_updated.csv' and 'spouse_updated.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b736b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset Head:\n",
      "  organ.                               werkgebied en -soort  werkperiode  \\\n",
      "0    GZB  Rantepao (Sulsel), verpleegster † in Japanse i...    1932-1933   \n",
      "1    NaN                                                NaN          NaN   \n",
      "2    NZG                                               Deli    1937-1946   \n",
      "3     SZ                    Bojonegoro, verpleegster in Zzh  1939-1942/6   \n",
      "4  ABCFM                              Batavia, bij Medhurst         1831   \n",
      "\n",
      "                                      bijzonderheden  id  \n",
      "0  ~ 1933 F.R.O. Steller, contr. BB, z.v. hp E.T....   0  \n",
      "1                                                NaN   0  \n",
      "2                        1942-45 Japanse internering   1  \n",
      "3  > dir. Centraal Zh in Hollan­dia (Dake 64) > S...   2  \n",
      "4                                                NaN   3  \n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "# Load the dataset from CSV.\n",
    "data_file = '/Volumes/Extreme SSD/Python_Projects/NIAA Project/FINAL Data (with annotations)/event_data_cleaned_with_gaps - Sheet1.csv'\n",
    "df = pd.read_csv(data_file)\n",
    "\n",
    "# Display the first few rows to verify the structure.\n",
    "print(\"Original Dataset Head:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c5f9ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after replacing empty strings:\n",
      "  organ.                               werkgebied en -soort  werkperiode  \\\n",
      "0    GZB  Rantepao (Sulsel), verpleegster † in Japanse i...    1932-1933   \n",
      "1    NaN                                                NaN          NaN   \n",
      "2    NZG                                               Deli    1937-1946   \n",
      "3     SZ                    Bojonegoro, verpleegster in Zzh  1939-1942/6   \n",
      "4  ABCFM                              Batavia, bij Medhurst         1831   \n",
      "\n",
      "                                      bijzonderheden  id  \n",
      "0  ~ 1933 F.R.O. Steller, contr. BB, z.v. hp E.T....   0  \n",
      "1                                                NaN   0  \n",
      "2                        1942-45 Japanse internering   1  \n",
      "3  > dir. Centraal Zh in Hollan­dia (Dake 64) > S...   2  \n",
      "4                                                NaN   3  \n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "# Replace empty strings (or strings with only whitespace) with NaN.\n",
    "df_clean = df.replace(r'^\\s*$', pd.NA, regex=True)\n",
    "\n",
    "# Optional: display a summary to check that empty strings have been replaced.\n",
    "print(\"Dataset after replacing empty strings:\")\n",
    "print(df_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8248b3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows to remove (only id present): 104\n",
      "\n",
      "Cleaned Dataset Head:\n",
      "    organ.                               werkgebied en -soort  werkperiode  \\\n",
      "0      GZB  Rantepao (Sulsel), verpleegster † in Japanse i...    1932-1933   \n",
      "1      NZG                                               Deli    1937-1946   \n",
      "2       SZ                    Bojonegoro, verpleegster in Zzh  1939-1942/6   \n",
      "3    ABCFM                              Batavia, bij Medhurst         1831   \n",
      "4  mandiri                       pred. gem. Temanggung, MJava    1925-1942   \n",
      "\n",
      "                                      bijzonderheden  id  \n",
      "0  ~ 1933 F.R.O. Steller, contr. BB, z.v. hp E.T....   0  \n",
      "1                        1942-45 Japanse internering   1  \n",
      "2  > dir. Centraal Zh in Hollan­dia (Dake 64) > S...   2  \n",
      "3                                                NaN   3  \n",
      "4                                       EndSumba 839   4  \n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "# Create a boolean mask identifying rows where columns other than \"id\" are all missing.\n",
    "# First, drop the \"id\" column and check for missing values across each row.\n",
    "mask_empty_others = df_clean.drop(columns=['id']).isna().all(axis=1)\n",
    "\n",
    "# Also ensure that the \"id\" column itself is not missing (meaning that the row contains an id).\n",
    "mask_only_id = mask_empty_others & df_clean['id'].notna()\n",
    "\n",
    "# Output number of rows that will be removed.\n",
    "rows_to_remove = mask_only_id.sum()\n",
    "print(f\"Rows to remove (only id present): {rows_to_remove}\")\n",
    "\n",
    "# Keep only rows that do NOT match the \"only id\" condition.\n",
    "df_filtered = df_clean[~mask_only_id].reset_index(drop=True)\n",
    "\n",
    "# Show the cleaned dataset.\n",
    "print(\"\\nCleaned Dataset Head:\")\n",
    "print(df_filtered.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bcce95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved as 'event_data_cleaned.csv'.\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "# Save the filtered dataframe to CSV.\n",
    "df_filtered.to_csv('/Volumes/Extreme SSD/Python_Projects/NIAA Project/FINAL/event_data_cleaned.csv', index=False)\n",
    "print(\"Cleaned dataset saved as 'event_data_cleaned.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
